{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f33b001-26f4-419c-a34c-ca626249e068",
   "metadata": {},
   "source": [
    "# Detection of slow-moving objects with LSST\n",
    "\n",
    "<div>\n",
    "<img src=\"logo_LSST.png\" width=\"450\"/>        \n",
    "</div>\n",
    "\n",
    "**Contact Author**: Antonio Vanzanella \n",
    "\n",
    "**Description**: This tutorial introduces the procedure of sample creation for a Dataset used to train and test a Machine learning pipeline able to detect simulated Slow-moving objects injected in the samples.  \n",
    "\n",
    "**LSST Data Products**: Images (calexp, skyMap, MaskedImage) and Catalogs (objectTable)\n",
    "\n",
    "**Packages**: `lsst.sphgeom`, `lsst.geom`, `lsst.afw.image`, `lsst.afw.display`, `lsst.skymap`, `lsst.daf.butler`, `scipy.interpolate`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03edaa69-f51c-431c-be4e-4542a0829267",
   "metadata": {},
   "source": [
    "## This Notebook\n",
    "In this notebook we showed how to retrieve and collect a series of cut-outs from a sequence of images at the same sky coordinates ordered by time, <br> compressing them into archives and giving some insights on how we used them to build a Dataset and how we trained a 3D-CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900922df-8c4c-430f-b9eb-e16b17cd73ae",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "A dataset is a collection of data. Building a dataset is crucial for any machine learning application and It is the most time-consuming task. <br> Starting from the simulated images and the expected physical characteristics of the objects which we are interested in detecting, we begin to define the principal aspect that our dataset will have to need.\n",
    "<br> First of all, we have to take into account the characteristics that the neural network will learn from it in its training phase. <br> We don't have much prior information about the slow-moving objects but we know that the most recognizable feature is their movement; then the problem becomes \"what kind of sample could describe our object?\"\n",
    "<br>  The solution we found is using an LSST-simulated image representing the background and injecting into it a simulated slow-moving object. <br> To describe the object's movement, we build a kind of \"video\" collecting many of these images resulting in a sequence of frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b8ae6-97bc-43c2-a725-abc16ac2685e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T19:12:58.398837Z",
     "iopub.status.busy": "2023-04-25T19:12:58.397850Z",
     "iopub.status.idle": "2023-04-25T19:12:58.403295Z",
     "shell.execute_reply": "2023-04-25T19:12:58.402618Z",
     "shell.execute_reply.started": "2023-04-25T19:12:58.398802Z"
    },
    "tags": []
   },
   "source": [
    "## The whole picture\n",
    "\n",
    "A deep Neural Network needs a lot of training samples(Training-set) to give good performances, so we put the whole procedure for creating a sample in a unique, great loop.\n",
    "In this notebook, we split the code into small fragments to provide a better explanation of the single parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bfe6e-6838-40b6-a848-9fd7ffe4275b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "pandas.set_option('display.max_rows', 1000)\n",
    "from IPython.display import Markdown as md\n",
    "from lsst.rsp import get_tap_service, retrieve_query\n",
    "import lsst.daf.butler as dafButler\n",
    "import lsst.geom\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from random import randrange, uniform\n",
    "import lsst.afw.display as afwDisplay\n",
    "import lsst.afw.image as afwImage\n",
    "import lsst.afw.table as afwTable\n",
    "import astropy.time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from lsst.skymap import makeSkyPolygonFromBBox\n",
    "lsst.afw.geom\n",
    "import math\n",
    "from astropy.io import fits\n",
    "import lsst.sphgeom\n",
    "import warnings\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import Angle\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import glob\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "for g in range(0,10):\n",
    "    repo = 'dp02'  \n",
    "    collection='2.2i/runs/DP0.2'\n",
    "    butler = dafButler.Butler(repo,collections=collection)\n",
    "    registry = butler.registry\n",
    "    rand_RA = uniform(50,74)  #60.2837946\n",
    "    rand_DEC =uniform(-44,-27) #-35.4042439\n",
    "    pixelization = lsst.sphgeom.HtmPixelization(12)\n",
    "    htm_id = pixelization.index(\n",
    "        lsst.sphgeom.UnitVector3d(\n",
    "            lsst.sphgeom.LonLat.fromDegrees(rand_RA, rand_DEC)   \n",
    "        )\n",
    "    )\n",
    "    t = astropy.time.core.Time(\"2025-09-05 08:16:03.643200\")\n",
    "    minute = astropy.time.TimeDelta(60, format=\"sec\")\n",
    "    timespan = dafButler.Timespan(t - minute*1051200,t + minute*1051200) #4 years\n",
    "    datasetRefs1 = registry.queryDatasets(\"calexp\", htm20=htm_id,\n",
    "                                             where=\"visit.timespan OVERLAPS my_timespan\",\n",
    "                                             bind={\"my_timespan\": timespan})\n",
    "    record_query= []  \n",
    "    for i, ref in enumerate(datasetRefs1):\n",
    "        record_query.append(ref)\n",
    "    point = lsst.geom.SpherePoint(rand_RA,rand_DEC, lsst.geom.degrees)\n",
    "    cutout = []\n",
    "    cutout1 = []\n",
    "    cutout2 = []\n",
    "    \n",
    "    dataId = {'visit': record_query[0].dataId['visit'], 'detector': record_query[0].dataId['detector'], 'band': record_query[0].dataId['band']}#, 'physical_filter':(record_query[1]).dataId['physical_filter']}\n",
    "    xx= butler.get('calexp', dataId=dataId)\n",
    "    wwcs = xx.getWcs()\n",
    "    w,h = xx.image.getDimensions()\n",
    "    bbox = lsst.geom.Box2I(lsst.geom.Point2I(0, 0), lsst.geom.Extent2I(w, h))\n",
    "    \n",
    "    ddim= 50\n",
    "    for i in range(0,len(record_query)):\n",
    "        dataId = {'visit': record_query[i].dataId['visit'], 'detector': record_query[i].dataId['detector']}\n",
    "        xx= butler.get('calexp', dataId= registry.expandDataId(dataId))\n",
    "        radec= lsst.geom.SpherePoint(rand_RA*lsst.geom.degrees, rand_DEC*lsst.geom.degrees)\n",
    "        x,y =xx.getWcs().skyToPixel(radec)  \n",
    "        wwcs = xx.getWcs()\n",
    "        # Define a small region for a cutout\n",
    "        bbox1 = lsst.geom.Box2I(lsst.geom.Point2I(x-(ddim/2), y-(ddim/2)), lsst.geom.Extent2I(ddim,ddim))\n",
    "        poly = makeSkyPolygonFromBBox(bbox, wwcs) \n",
    "        if poly.contains(point.getVector()):\n",
    "            try:\n",
    "                tmp  = xx.Factory(xx, bbox1, origin=afwImage.LOCAL, deep=False)\n",
    "                cutout.append(tmp.image.array.flatten())\n",
    "                cutout1.append(xx.visitInfo.getDate().get(lsst.daf.base.DateTime.MJD, lsst.daf.base.DateTime.UTC))\n",
    "                cutout2.append(xx.visitInfo.getDate())     \n",
    "            except:\n",
    "                print(\"the cutout has exceeded the dimension of the image\")\n",
    "                \n",
    "    # take date element\n",
    "    from datetime import datetime\n",
    "    def takeSecond(elem):\n",
    "        #date = datetime.strptime(elem.visitInfo.getDate().strftime(\"%m/%d/%Y, %H:%M:%S\"),'%Y-%m-%d %H:%M:%S')\n",
    "        return elem.get(lsst.daf.base.DateTime.MJD, lsst.daf.base.DateTime.UTC)\n",
    "    cutout2.sort(key= takeSecond)\n",
    "    cut = zip(cutout1, cutout)\n",
    "    try:\n",
    "        #cut1 = sorted(cut)\n",
    "        sort_cut = [element for _, element in sorted(cut)]\n",
    "\n",
    "        ix= np.arange(ddim,dtype=float)\n",
    "        iy= np.arange(ddim,dtype=float)\n",
    "        pixPointList = [lsst.geom.Point2D(u, v) for u in ix for v in iy]\n",
    "        \n",
    "        dataId = {'visit': record_query[0].dataId['visit'], 'detector': record_query[0].dataId['detector']}\n",
    "        xx= butler.get('calexp', dataId= registry.expandDataId(dataId))\n",
    "        spherePoints = xx.getWcs().pixelToSky(pixPointList)\n",
    "        #parentSkyPos =  cutout[0].getWcs().pixelToSkyArray(ix,iy,degrees=True)\n",
    "        r_m=[u.getRa().asDegrees() for u in spherePoints]\n",
    "        d_m=[u.getDec().asDegrees() for u in spherePoints]\n",
    "\n",
    "        animation= []\n",
    "\n",
    "        dim_grid=15\n",
    "        X= np.zeros((dim_grid,dim_grid))\n",
    "        Y= np.zeros((dim_grid,dim_grid))\n",
    "\n",
    "        for i in range(dim_grid):\n",
    "            for j in range(dim_grid):\n",
    "                X[i,j]=spherePoints[(i*ddim+j)].getRa().asDegrees()\n",
    "        for i in range(dim_grid):\n",
    "            for j in range(dim_grid):\n",
    "                Y[i,j]=spherePoints[(i*ddim+j)].getDec().asDegrees()\n",
    "\n",
    "        for i in sort_cut:\n",
    "            im = griddata((r_m,d_m),i,(X,Y),method='cubic',fill_value= np.mean(i))\n",
    "            animation.append(im)\n",
    "        \n",
    "        #replace the path folder with local path folder\n",
    "        #in the local path folder run mkir DATA\n",
    "        #in the local path folder run mkir PLOT        \n",
    "        !rm /home/antoniovanzanella/DATA/*.fits\n",
    "        !rm /home/antoniovanzanella/PLOT/*.png\n",
    "\n",
    "        for y in range(0,len(animation)):\n",
    "            hdu = fits.PrimaryHDU(animation[y])\n",
    "            hdu.header['DATE'] = str(cutout2[y])\n",
    "            hdu.header[''] = str(rand_RA)\n",
    "            hdu.header['COMMENT'] = str(rand_DEC)\n",
    "            hdul = fits.HDUList([hdu])\n",
    "        \n",
    "            #replace the path folder with local path folder\n",
    "        \n",
    "            hdul.writeto(\"/home/avanzan/DATA/new%02d.fits\" %y)\n",
    "            fits_image=\"/home/avanzan/DATA/new00.fits\"\n",
    "            plt.title(cutout2[y])\n",
    "            plt.imshow(animation[y], cmap='gray', vmin=-100.0, vmax=200, origin='lower')\n",
    "            plt.savefig(\"/home/avanzan/PLOT/test%02d.png\" %y, cmap='gray', vmin=-100.0, vmax=200, origin='lower')\n",
    "            #plt.show()\n",
    "\n",
    "        numbers = re.compile(r'(\\d+)')\n",
    "    \n",
    "        def numericalSort(value):\n",
    "            parts = numbers.split(value)\n",
    "            parts[1::2] = map(int, parts[1::2])\n",
    "            return parts\n",
    "\n",
    "        def make_gif(frame_folder):\n",
    "            frames = [Image.open(image) for image in sorted(glob.glob(f\"{frame_folder}/*.png\"),key= numericalSort)]\n",
    "            frame_one = frames[0]\n",
    "            frame_one.save(\"interp.gif\", format=\"GIF\", append_images=frames,\n",
    "                       save_all=True, duration=700, loop=0)\n",
    "\n",
    "        make_gif(\"/home/avanzan/PLOT/\")  \n",
    "        name = \"samples_\"+ str(g)+\".tar.gz\"\n",
    "        !export name\n",
    "        !tar -czf $name DATA\n",
    "    except:\n",
    "        print(\"EMPTY SEQUENCE\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9bbc0-802a-4f53-a658-021825ec0001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T19:12:58.398837Z",
     "iopub.status.busy": "2023-04-25T19:12:58.397850Z",
     "iopub.status.idle": "2023-04-25T19:12:58.403295Z",
     "shell.execute_reply": "2023-04-25T19:12:58.402618Z",
     "shell.execute_reply.started": "2023-04-25T19:12:58.398802Z"
    },
    "tags": []
   },
   "source": [
    "# Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b796972-2d05-4983-9547-babc70c34a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T19:12:58.398837Z",
     "iopub.status.busy": "2023-04-25T19:12:58.397850Z",
     "iopub.status.idle": "2023-04-25T19:12:58.403295Z",
     "shell.execute_reply": "2023-04-25T19:12:58.402618Z",
     "shell.execute_reply.started": "2023-04-25T19:12:58.398802Z"
    },
    "tags": []
   },
   "source": [
    "## Preliminary operations\n",
    "First of all, we imported all the libraries to query and process the LSST data.\n",
    "Furthermore, other packages were used to interpolate and stack the samples and to handle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db0c798d-2367-4af3-a791-0ec616d276ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:13:27.919758Z",
     "iopub.status.busy": "2023-04-28T15:13:27.918838Z",
     "iopub.status.idle": "2023-04-28T15:13:27.924475Z",
     "shell.execute_reply": "2023-04-28T15:13:27.923670Z",
     "shell.execute_reply.started": "2023-04-28T15:13:27.919726Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#to handle and process LSST data\n",
    "import lsst.daf.butler as dafButler\n",
    "import lsst.sphgeom\n",
    "import astropy.time\n",
    "import lsst.geom\n",
    "import lsst.afw.display as afwDisplay\n",
    "import lsst.afw.image as afwImage\n",
    "from lsst.skymap import makeSkyPolygonFromBBox\n",
    "\n",
    "#to interpolate the data\n",
    "from scipy.interpolate import griddata \n",
    "from astropy.io import fits\n",
    "\n",
    "#to handle files and display images\n",
    "from random import uniform\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f39b8d-c466-4953-a117-263c93d23838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T17:37:55.676149Z",
     "iopub.status.busy": "2023-04-25T17:37:55.675287Z",
     "iopub.status.idle": "2023-04-25T17:37:58.117165Z",
     "shell.execute_reply": "2023-04-25T17:37:58.116455Z",
     "shell.execute_reply.started": "2023-04-25T17:37:55.676120Z"
    },
    "tags": []
   },
   "source": [
    "Using butler to connect with the DP0.2 repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cb173b3-9ec5-411b-82f7-e7fc01ee87b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:13:28.976333Z",
     "iopub.status.busy": "2023-04-28T15:13:28.975527Z",
     "iopub.status.idle": "2023-04-28T15:13:31.160304Z",
     "shell.execute_reply": "2023-04-28T15:13:31.159592Z",
     "shell.execute_reply.started": "2023-04-28T15:13:28.976303Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo = 'dp02'  \n",
    "collection='2.2i/runs/DP0.2'\n",
    "butler = dafButler.Butler(repo,collections=collection)\n",
    "registry = butler.registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d87483f-69fe-4464-8f13-a6f5f6e36e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T17:37:55.676149Z",
     "iopub.status.busy": "2023-04-25T17:37:55.675287Z",
     "iopub.status.idle": "2023-04-25T17:37:58.117165Z",
     "shell.execute_reply": "2023-04-25T17:37:58.116455Z",
     "shell.execute_reply.started": "2023-04-25T17:37:55.676120Z"
    },
    "tags": []
   },
   "source": [
    "## The query\n",
    "\n",
    "We pick a random coordinates pair in the LSST simulated sky and we chose a correct pixelization around that point.\n",
    "We use a specific level(12) of the HTM (hierarchical triangular mesh) pixelization of the sky ([HTM primer](http://www.skyserver.org/htm/)).\n",
    "<br>\"The process is to transform a region or point into one or more HTM identifiers (HTM IDs), and then create a query using the HTM ID as the spatial data ID.\n",
    "The `lsst.sphgeom` library supports region objects and HTM pixelization in the LSST Science Pipelines.\"<br>(Taken from the **04_Intro_to_Butler** notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d28630b7-2291-4406-b55e-8b6248b64b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:13:31.227501Z",
     "iopub.status.busy": "2023-04-28T15:13:31.227255Z",
     "iopub.status.idle": "2023-04-28T15:13:31.231425Z",
     "shell.execute_reply": "2023-04-28T15:13:31.230839Z",
     "shell.execute_reply.started": "2023-04-28T15:13:31.227483Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RA_lower_limit = 50\n",
    "RA_upper_limit = 74\n",
    "DEC_lower_limit = -44\n",
    "DEC_upper_limit = -27\n",
    "rand_RA = uniform(RA_lower_limit,RA_upper_limit)\n",
    "rand_DEC =uniform(DEC_lower_limit,DEC_upper_limit) \n",
    "pixelization = lsst.sphgeom.HtmPixelization(12)\n",
    "htm_id = pixelization.index(\n",
    "    lsst.sphgeom.UnitVector3d(\n",
    "        lsst.sphgeom.LonLat.fromDegrees(rand_RA, rand_DEC)   \n",
    "    )\n",
    ")\n",
    "\n",
    "#scale = pixelization.triangle(htm_id).getBoundingCircle().getOpeningAngle().asDegrees()*3600\n",
    "#print(f'HTM ID={htm_id} at level={pixelization.getLevel()} is a ~{scale:0.2}\" triangle.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459a6a2e-1e8b-4c4e-8bff-f823608a2786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T21:54:06.072766Z",
     "iopub.status.busy": "2023-04-25T21:54:06.071880Z",
     "iopub.status.idle": "2023-04-25T21:54:06.084082Z",
     "shell.execute_reply": "2023-04-25T21:54:06.083436Z",
     "shell.execute_reply.started": "2023-04-25T21:54:06.072736Z"
    },
    "tags": []
   },
   "source": [
    "Now, we set a reference time.\n",
    "Then we make a query to obtain all the calexp images observed during the chosen time period(e.g. roughly 4 years)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc81ccb7-5f44-4214-897d-a15996769161",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:13:31.232871Z",
     "iopub.status.busy": "2023-04-28T15:13:31.232515Z",
     "iopub.status.idle": "2023-04-28T15:13:31.280636Z",
     "shell.execute_reply": "2023-04-28T15:13:31.280007Z",
     "shell.execute_reply.started": "2023-04-28T15:13:31.232851Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/lsst/software/stack/conda/miniconda3-py38_4.9.2/envs/lsst-scipipe-5.1.0/lib/python3.10/site-packages/erfa/core.py:154: ErfaWarning: ERFA function \"taiutc\" yielded 1 of \"dubious year (Note 4)\"\n",
      "  warnings.warn('ERFA function \"{}\" yielded {}'.format(func_name, wmsg),\n"
     ]
    }
   ],
   "source": [
    "t = astropy.time.core.Time(\"2025-09-05 08:16:03.643200\")\n",
    "\n",
    "minute = astropy.time.TimeDelta(60, format=\"sec\")\n",
    "timespan = dafButler.Timespan(t - minute*1051200,t + minute*1051200)#4 years\n",
    "#timespan = dafButler.Timespan(t - minute*2600000,t + minute*2600000)#10 years\n",
    "#timespan = dafButler.Timespan(t - minute*525600,t + minute*525600)#1 years\n",
    "\n",
    "datasetRefs1 = registry.queryDatasets(\"calexp\", htm20=htm_id,\n",
    "                                         where=\"visit.timespan OVERLAPS my_timespan\",\n",
    "                                         bind={\"my_timespan\": timespan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d5203-aa06-4392-b10f-7d0b4e35b36c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T17:37:58.215186Z",
     "iopub.status.busy": "2023-04-25T17:37:58.214957Z",
     "iopub.status.idle": "2023-04-25T17:39:01.264798Z",
     "shell.execute_reply": "2023-04-25T17:39:01.263661Z",
     "shell.execute_reply.started": "2023-04-25T17:37:58.215167Z"
    },
    "tags": []
   },
   "source": [
    "All the  retrieved images are saved in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "449e959d-0254-42fd-b723-968712c9ec67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:13:31.449034Z",
     "iopub.status.busy": "2023-04-28T15:13:31.448056Z",
     "iopub.status.idle": "2023-04-28T15:14:05.145640Z",
     "shell.execute_reply": "2023-04-28T15:14:05.144814Z",
     "shell.execute_reply.started": "2023-04-28T15:13:31.448995Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "record_query= []  \n",
    "for i, ref in enumerate(datasetRefs1):\n",
    "    record_query.append(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39cd5fc5-d4bc-4fa5-b111-a96828ead311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:14:05.346982Z",
     "iopub.status.busy": "2023-04-28T15:14:05.346751Z",
     "iopub.status.idle": "2023-04-28T15:14:05.351260Z",
     "shell.execute_reply": "2023-04-28T15:14:05.350429Z",
     "shell.execute_reply.started": "2023-04-28T15:14:05.346964Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540\n"
     ]
    }
   ],
   "source": [
    "print(len(record_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964641ad-9583-4592-bd7d-583cf79370a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T17:39:01.453859Z",
     "iopub.status.busy": "2023-04-25T17:39:01.453601Z",
     "iopub.status.idle": "2023-04-25T17:39:01.457486Z",
     "shell.execute_reply": "2023-04-25T17:39:01.456801Z",
     "shell.execute_reply.started": "2023-04-25T17:39:01.453838Z"
    },
    "tags": []
   },
   "source": [
    "## Manage data\n",
    "\n",
    "These lists will contain the flattened images, the Julian dates, and the UTC respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3de2c671-382b-4b78-8642-d34c276e37c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:14:05.352613Z",
     "iopub.status.busy": "2023-04-28T15:14:05.352361Z",
     "iopub.status.idle": "2023-04-28T15:14:05.370159Z",
     "shell.execute_reply": "2023-04-28T15:14:05.369427Z",
     "shell.execute_reply.started": "2023-04-28T15:14:05.352594Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutout = []\n",
    "cutout_date_MJD = []\n",
    "cutout_date = []\n",
    "\n",
    "point = lsst.geom.SpherePoint(rand_RA,rand_DEC, lsst.geom.degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868370e0-342b-43aa-9bf2-74194475496b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T17:39:18.734689Z",
     "iopub.status.busy": "2023-04-25T17:39:18.734012Z",
     "iopub.status.idle": "2023-04-25T17:39:20.637351Z",
     "shell.execute_reply": "2023-04-25T17:39:20.636626Z",
     "shell.execute_reply.started": "2023-04-25T17:39:18.734661Z"
    },
    "tags": []
   },
   "source": [
    "For each calexp \"record\" we asked for the respective image and its metadata; using lsst.geom we defined an interest region,\n",
    "<br> a squared bounding box mapped on the sky all around the chosen point.\n",
    "To be able to work with this information we converted the coords into pixels and define a box to delimit the portion of the image we want to extract(the cut-out).\n",
    "<br>Then we append to the list the image and the linked information only if the area is contained in the current image. Otherwise, an exception is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72c79e7f-b226-42d7-9d1c-f75311e9c8c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:14:05.371670Z",
     "iopub.status.busy": "2023-04-28T15:14:05.371287Z",
     "iopub.status.idle": "2023-04-28T15:15:36.034800Z",
     "shell.execute_reply": "2023-04-28T15:15:36.033696Z",
     "shell.execute_reply.started": "2023-04-28T15:14:05.371644Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n",
      "the cutout has exceeded the dimension of the image\n"
     ]
    }
   ],
   "source": [
    "#ddim= 100\n",
    "ddim= 50\n",
    "#It requires too much time.\n",
    "#for i in range(0,len(record_query)):\n",
    "for i in range(0,50):\n",
    "    dataId = {'visit': record_query[i].dataId['visit'], 'detector': record_query[i].dataId['detector']}\n",
    "    xx= butler.get('calexp', dataId= registry.expandDataId(dataId))\n",
    "    radec= lsst.geom.SpherePoint(rand_RA*lsst.geom.degrees, rand_DEC*lsst.geom.degrees)\n",
    "    x,y =xx.getWcs().skyToPixel(radec)  \n",
    "    wwcs = xx.getWcs()\n",
    "    # Define a small region for a cutout\n",
    "    bbox1 = lsst.geom.Box2I(lsst.geom.Point2I(x-(ddim/2), y-(ddim/2)), lsst.geom.Extent2I(ddim,ddim))\n",
    "    poly = makeSkyPolygonFromBBox(bbox1, wwcs) \n",
    "    if poly.contains(point.getVector()):\n",
    "        try:\n",
    "            tmp  = xx.Factory(xx, bbox1, origin=afwImage.LOCAL, deep=False)\n",
    "            cutout.append(tmp.image.array.flatten())\n",
    "            cutout_date_MJD.append(xx.visitInfo.getDate().get(lsst.daf.base.DateTime.MJD, lsst.daf.base.DateTime.UTC))\n",
    "            cutout_date.append(xx.visitInfo.getDate())     \n",
    "        except:\n",
    "            print(\"the cutout has exceeded the dimension of the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8ef919a-3d20-4cde-a598-7d83653569f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:15:36.036351Z",
     "iopub.status.busy": "2023-04-28T15:15:36.036065Z",
     "iopub.status.idle": "2023-04-28T15:15:36.040728Z",
     "shell.execute_reply": "2023-04-28T15:15:36.039896Z",
     "shell.execute_reply.started": "2023-04-28T15:15:36.036326Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(cutout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce52880-c473-44f5-8ac0-3a8617b239df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T18:15:36.778979Z",
     "iopub.status.busy": "2023-04-25T18:15:36.778061Z",
     "iopub.status.idle": "2023-04-25T18:15:36.783093Z",
     "shell.execute_reply": "2023-04-25T18:15:36.782150Z",
     "shell.execute_reply.started": "2023-04-25T18:15:36.778949Z"
    },
    "tags": []
   },
   "source": [
    "Here we implemented a function that returns the value in the data field.<br>\n",
    "Subsequently, this will be used to sort the list by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63007394-3bc3-4523-8b43-16a81785423e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:15:36.042027Z",
     "iopub.status.busy": "2023-04-28T15:15:36.041785Z",
     "iopub.status.idle": "2023-04-28T15:15:36.060881Z",
     "shell.execute_reply": "2023-04-28T15:15:36.059970Z",
     "shell.execute_reply.started": "2023-04-28T15:15:36.042008Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def takeSecond(elem):\n",
    "    return elem.get(lsst.daf.base.DateTime.MJD, lsst.daf.base.DateTime.UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab2e544e-5701-42b8-95f5-c1c39da53087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:15:36.063280Z",
     "iopub.status.busy": "2023-04-28T15:15:36.062969Z",
     "iopub.status.idle": "2023-04-28T15:15:36.080887Z",
     "shell.execute_reply": "2023-04-28T15:15:36.080164Z",
     "shell.execute_reply.started": "2023-04-28T15:15:36.063255Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutout_date.sort(key= takeSecond)\n",
    "cut = zip(cutout_date_MJD, cutout)\n",
    "\n",
    "cut1 = sorted(cut)\n",
    "sort_cut = [element for _, element in cut1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff713b5-6d46-4689-981c-58e7be22298f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T18:15:36.778979Z",
     "iopub.status.busy": "2023-04-25T18:15:36.778061Z",
     "iopub.status.idle": "2023-04-25T18:15:36.783093Z",
     "shell.execute_reply": "2023-04-25T18:15:36.782150Z",
     "shell.execute_reply.started": "2023-04-25T18:15:36.778949Z"
    },
    "tags": []
   },
   "source": [
    "## Interpolation\n",
    "\n",
    "Then we create a mask of points to interpolate the images choosing a random image to initialize the procedure.\n",
    "<br> Using lstm.geom we generate two arrays of points that are converted in RA and DEC coordinates according to the current image properties.\n",
    "Defining two small grids for RA and DEC in degrees, we apply a bicubic interpolation (griddata, https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.griddata.html )<br> to our cut-outs.\n",
    "We made this since the different times when the images are observed produced a sequence of images in which the sky rotated and translated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04dda431-5435-47ec-aa62-c3f6eb08a92f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:15:36.082045Z",
     "iopub.status.busy": "2023-04-28T15:15:36.081798Z",
     "iopub.status.idle": "2023-04-28T15:15:38.163844Z",
     "shell.execute_reply": "2023-04-28T15:15:38.163036Z",
     "shell.execute_reply.started": "2023-04-28T15:15:36.082024Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ix= np.arange(ddim,dtype=float)\n",
    "iy= np.arange(ddim,dtype=float)\n",
    "\n",
    "pixPointList = [lsst.geom.Point2D(u, v) for u in ix for v in iy]\n",
    "\n",
    "#we choose a random image to embed our grid.\n",
    "dataId = {'visit': record_query[0].dataId['visit'], 'detector': record_query[0].dataId['detector']}\n",
    "xx= butler.get('calexp', dataId= registry.expandDataId(dataId))\n",
    "spherePoints = xx.getWcs().pixelToSky(pixPointList)\n",
    "#the reverse operation \n",
    "#parentSkyPos =  cutout[0].getWcs().pixelToSkyArray(ix,iy,degrees=True)\n",
    "\n",
    "r_m=[u.getRa().asDegrees() for u in spherePoints]\n",
    "d_m=[u.getDec().asDegrees() for u in spherePoints]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a3be5-64ec-4702-b3df-ca538625ea9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T18:15:36.778979Z",
     "iopub.status.busy": "2023-04-25T18:15:36.778061Z",
     "iopub.status.idle": "2023-04-25T18:15:36.783093Z",
     "shell.execute_reply": "2023-04-25T18:15:36.782150Z",
     "shell.execute_reply.started": "2023-04-25T18:15:36.778949Z"
    },
    "tags": []
   },
   "source": [
    "The interpolation is a lossy function and this is the reason why we took a much larger area than the cut-outs from the images in the previous code fragments.\n",
    "<br> The final cut-outs are 15 by 15 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9b200c0-4e19-4866-be37-f1cb0a1805c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:15:38.165066Z",
     "iopub.status.busy": "2023-04-28T15:15:38.164800Z",
     "iopub.status.idle": "2023-04-28T15:15:39.055723Z",
     "shell.execute_reply": "2023-04-28T15:15:39.054909Z",
     "shell.execute_reply.started": "2023-04-28T15:15:38.165045Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "animation= []\n",
    "\n",
    "dim_grid=15\n",
    "X= np.zeros((dim_grid,dim_grid))\n",
    "Y= np.zeros((dim_grid,dim_grid))\n",
    "\n",
    "for i in range(dim_grid):\n",
    "    for j in range(dim_grid):\n",
    "        X[i,j]=spherePoints[(i*ddim+j)].getRa().asDegrees()\n",
    "for i in range(dim_grid):\n",
    "    for j in range(dim_grid):\n",
    "        Y[i,j]=spherePoints[(i*ddim+j)].getDec().asDegrees()\n",
    "\n",
    "for i in sort_cut:\n",
    "    im = griddata((r_m,d_m),i,(X,Y),method='cubic',fill_value= np.mean(i))\n",
    "    animation.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb70d4-ced6-4a7f-9741-73482c861de6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-28T15:15:48.793973Z",
     "iopub.status.idle": "2023-04-28T15:15:48.794226Z",
     "shell.execute_reply": "2023-04-28T15:15:48.794114Z",
     "shell.execute_reply.started": "2023-04-28T15:15:48.794103Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(animation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bde9dc-e3c0-4f3a-b762-a12109b68cc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T18:15:36.778979Z",
     "iopub.status.busy": "2023-04-25T18:15:36.778061Z",
     "iopub.status.idle": "2023-04-25T18:15:36.783093Z",
     "shell.execute_reply": "2023-04-25T18:15:36.782150Z",
     "shell.execute_reply.started": "2023-04-25T18:15:36.778949Z"
    },
    "tags": []
   },
   "source": [
    "## Data storage \n",
    "\n",
    "All the images produced are stacked to build a single sample. By finding ourselves in a cycle we need to remove old images and this explains the presence of the rm command at the beginning of the section.<br> Later, for each image in the sequence we save it in a **fits** file using the `astropy.io` library.\n",
    "The header is used to save time and coordinates information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5c57f-ccaa-43a9-bff0-6dc18d1d9ad3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-28T15:15:48.794989Z",
     "iopub.status.idle": "2023-04-28T15:15:48.795247Z",
     "shell.execute_reply": "2023-04-28T15:15:48.795135Z",
     "shell.execute_reply.started": "2023-04-28T15:15:48.795124Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#replace the path folder with local path folder\n",
    "#\n",
    "!rm /home/avanzan/DATA/*.fits\n",
    "!rm /home/avanzan/PLOT/*.png\n",
    "\n",
    "for y in range(0,len(animation)):\n",
    "    hdu = fits.PrimaryHDU(animation[y])\n",
    "    hdu.header['DATE'] = str(cutout_date[y])\n",
    "    hdu.header[''] = str(rand_RA)\n",
    "    hdu.header['COMMENT'] = str(rand_DEC)\n",
    "    #hdu.header['RA'] = str(rand_RA)\n",
    "    #dhu.header['DEC']= str(rand_DEC)\n",
    "    hdul = fits.HDUList([hdu])\n",
    "    hdul.writeto(\"/home/avanzan/DATA/new%02d.fits\" %y)\n",
    "    fits_image=\"/home/avanzan/DATA/new00.fits\"\n",
    "    plt.title(cutout_date[y])\n",
    "    plt.imshow(animation[y], cmap='gray', vmin=-100.0, vmax=200, origin='lower')\n",
    "    plt.savefig(\"/home/avanzan/PLOT/test%02d.png\" %y)\n",
    "                #, cmap='gray', vmin=-100.0, vmax=200, origin='lower')\n",
    "\n",
    "numbers = re.compile(r'(\\d+)') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db52e55-8567-4d8b-850e-79fac425c8cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T18:15:36.778979Z",
     "iopub.status.busy": "2023-04-25T18:15:36.778061Z",
     "iopub.status.idle": "2023-04-25T18:15:36.783093Z",
     "shell.execute_reply": "2023-04-25T18:15:36.782150Z",
     "shell.execute_reply.started": "2023-04-25T18:15:36.778949Z"
    },
    "tags": []
   },
   "source": [
    "We have two extra functions implemented to make a gif of the sample.<br> These, are not strictly necessary but we built them to have a visual output of our work.\n",
    "Finally, the sample is compressed using **tar** algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43886698-0719-44cb-8a58-8f662b1d813c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T15:16:23.860840Z",
     "iopub.status.busy": "2023-04-28T15:16:23.860481Z",
     "iopub.status.idle": "2023-04-28T15:16:25.433207Z",
     "shell.execute_reply": "2023-04-28T15:16:25.432057Z",
     "shell.execute_reply.started": "2023-04-28T15:16:23.860815Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def make_gif(frame_folder):\n",
    "    frames = [Image.open(image) for image in sorted(glob.glob(f\"{frame_folder}/*.png\"),key= numericalSort)]\n",
    "    frame_one = frames[0]\n",
    "    frame_one.save(\"interp.gif\", format=\"GIF\", append_images=frames,save_all=True, duration=700, loop=0)\n",
    "\n",
    "make_gif(\"/home/avanzan/PLOT\")  \n",
    "### g as input works only in the for loop\n",
    "#name = \"samples_\"+ str(g)+\".tar.gz\"\n",
    "name = \"samples_\"+ str(0)+\".tar.gz\"\n",
    "\n",
    "!export name\n",
    "!tar -czf $name DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ab9a6-31f3-49a8-9762-b5107517b20f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T18:15:36.778979Z",
     "iopub.status.busy": "2023-04-25T18:15:36.778061Z",
     "iopub.status.idle": "2023-04-25T18:15:36.783093Z",
     "shell.execute_reply": "2023-04-25T18:15:36.782150Z",
     "shell.execute_reply.started": "2023-04-25T18:15:36.778949Z"
    },
    "tags": []
   },
   "source": [
    "Iterating this procedure, we built a great amount of samples where we injected simulated Slow-moving objects starting from TNOs ephemeris taken from the JPL database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c28d0c-dbe6-490a-baf0-a8dfd0b2dd9e",
   "metadata": {},
   "source": [
    "## Slow moving objects injection\n",
    "\n",
    "<div>\n",
    "<img src=\"workflow.png\" width=\"500\"/>        \n",
    "</div>\n",
    "\n",
    "Unfortunately, the remaining part of the Dataset creation requires to move on a different hardware and this is the reason behind the file storage.\n",
    "As is possible to see in the upper figure, we used these samples as input in another function.\n",
    "<br> We use one of the **JPL** tools to query about all the: TNOs, Parabolic and Hyperbolic Asteroids, and Hyperbolic and Parabolic Comets present in the dataset. \n",
    "<br>Once obtained the objects and relative information, such as absolute magnitude, eccentricity, perihelion distance, semi-major axis, inclination, and so on, we store them in a **CSV** file. \n",
    "<br>Starting from this information we use the **astropy** library to compute the ephemerides of the objects every 24 hours for five years, taking care to overlap the range of time of computation with the one used for the query on the simulated LSST image;\n",
    "<br> then we save all the RA and DEC values in arrays as attributes of a python class together with the other object's information. \n",
    "<br>In this way, at the end we have a series of instances of a class, where each instance is a different celestial object with its ephemerides and physical characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec91a339-f0e0-4016-b373-fc78faddb980",
   "metadata": {},
   "source": [
    "Object injection into the images is first done by creating a 15x15 grid centered on zero and checking that each object falls during the sequence in the cutouts. \n",
    "<br>For this purpose we check the standard deviation of the grid and we make sure that its standard deviation is greater than the standard deviation of the arrays of right ascension and declination. \n",
    "<br>Then we paint the object on the grid using a PSF (Point Spread Function). We do this for each frame, by changing the position of the PSF on the basis of the ephemerides we downloaded from JPL.\n",
    "<br>However, since the objects we took from the JPL database are too close to us than what we would like to detect, we project them at a greater distance by changing a scaling factor during the injection.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"intime.png\" width=\"500\"/>        \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf29c1-41e3-47e1-9f56-30a63e98b5d4",
   "metadata": {},
   "source": [
    "The last step of the dataset population process is to overlap the grid containing the slow-moving object to the LSST image.\n",
    "<br>It is important to note that we want the movement described in the grids maintain the conceptual consistency of the LSST images;\n",
    "<br> this is the reason We made a function that perfectly matches the given observation date of the LSST images to one of the object ephemerides. \n",
    "<br>When there is no match, the function simply discards the grid from the sequence and goes on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972530b-820a-4b78-9de8-361dd7cd9674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T17:11:08.093313Z",
     "iopub.status.busy": "2023-04-26T17:11:08.092570Z",
     "iopub.status.idle": "2023-04-26T17:11:08.098015Z",
     "shell.execute_reply": "2023-04-26T17:11:08.097093Z",
     "shell.execute_reply.started": "2023-04-26T17:11:08.093282Z"
    }
   },
   "source": [
    "\n",
    "<div>\n",
    "<img src=\"sim.png\" width=\"500\"/>        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f84d77-89a8-4576-911e-7797d1f44d16",
   "metadata": {},
   "source": [
    "## 3D-CNN\n",
    "\n",
    "Beyond the classic structure that provides input-convolutional-fully connected layers, we applied 3D max-pooling to avoid the uncontrolled features map change of dimension;\n",
    "<br>dropout is strongly recommended to avoid the overfitting problem.\n",
    "<br>In fact, those data showed a great tendency to this phenomenon. Probably, It is caused by their similarity. \n",
    "<br>We also used batch normalization to avoid the shift covariance phenomenon and the L2-regularization.\n",
    "<br>After several of these blocks-like a dense(fully-connected) layer has been placed and after it, a single neuron able to make the binary classification. \n",
    "<br>ReLu was used as the activation function and the Binary cross-entropy as loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b423ff-aaeb-4ace-8f1a-171cdb1ca87f",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "<img src=\"CNN (2).png\" width=\"700\"/>        \n",
    "</div>\n",
    "\n",
    "\n",
    "The NN takes video as patterns, in particular a 50 frames series of 15 by 15 size forwarding them through the Convolutional blocks. \n",
    "<br>Each of the six convolutional layers increases the depth of the feature maps, starting from 16 filters in the first convolution to 512 in the last one. \n",
    "<br>After each convolution a batch normalization and a 3D max pooling are used. \n",
    "<br>Finally, a fully connected layer working on the flattened features maps is used in anticipation of the Sigmoid activation function in charge of providing output. As loss function a binary cross-entropy is used and a ReLu as activation function. \n",
    "<br>As output the network discriminates against sequences with the presence of the slow-moving object or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
